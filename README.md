
# ğŸ¤– PDF Insights: An Intelligent Conversational RAG Assistant

A conversational AI assistant powered by **LangChain + Groq + Chroma** that intelligently answers questions about your **uploaded PDFs** using Retrieval Augmented Generation (RAG).  
Built with **Streamlit** for a seamless, chat-like user interface.

---

## ğŸš€ Features

- Upload multiple PDFs and query them conversationally
- Retrieval Augmented Generation (RAG) pipeline with document chunking & embeddings
- Uses Chroma as vector store with persistent storage
- Supports session memory (chat history per session)
- Powered by Groq's LLMs + Hugging Face embeddings
- Clean, responsive Streamlit chat UI with message bubbles

---

## ğŸ› ï¸ Tech Stack

- [Streamlit](https://streamlit.io/) â€” UI Framework
- [LangChain](https://www.langchain.com/) â€” LLM chaining & RAG pipelines
- [Chroma](https://docs.trychroma.com/) â€” Vector store for document retrieval
- [Groq LLMs](https://console.groq.com/) â€” Fast inference backend
- [Hugging Face Embeddings](https://huggingface.co/) â€” Text embeddings (e.g., `all-MiniLM-L6-v2`)
- [PyPDFLoader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf) â€” PDF parsing

---

## ğŸ“¸ Demo Screenshot

<p align="center">
  <img src="Sample.png" alt="Conversational RAG Chatbot Screenshot" width="800"/>
</p>

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/conversational-rag-chatbot.git
cd conversational-rag-chatbot
```

### 2ï¸âƒ£ Install Requirements
It is recommended to use a virtual environment.

```bash
pip install -r requirements.txt
```

> âœ… Make sure to install versions compatible with LangChain & Chroma:
> - `langchain==0.1.14`
> - `chromadb==0.4.24`

### 3ï¸âƒ£ Configure `.env` file

Create a `.env` file in the root directory:

```dotenv
HF_TOKEN=your_huggingface_token_here
```

You can get a free HuggingFace token from [here](https://huggingface.co/settings/tokens).

### 4ï¸âƒ£ Run the App
```bash
streamlit run app.py
```

---

## ğŸ”‘ Authentication

- Enter your **Groq API Key** in the sidebar before starting chats.
- Upload your **PDF files** from the sidebar uploader.
- Start chatting with the bot in natural language!

---

## ğŸ’¾ Vector Store Persistence

- Uses **Chroma DB** with `./chroma_db` folder for vector storage.
- Ensures PDF embeddings persist across sessions.
- You can clear chat memory using the **ğŸ§¹ Clear Chat Memory** button.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                # Streamlit app (main entry)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                  # API keys (HF_TOKEN)
â”œâ”€â”€ chroma_db/            # Persisted vector database
â”œâ”€â”€ screenshot.png        # App screenshot
â””â”€â”€ README.md
```

---

## ğŸ”¥ Sample Models Used

- **Embeddings**: `all-MiniLM-L6-v2` (via Hugging Face)
- **LLM**: `Gemma2-9b-It` (served via Groq)

---

## ğŸ™ Acknowledgements

- [LangChain](https://www.langchain.com/)
- [Groq LLMs](https://groq.com/)
- [Chroma Vector DB](https://trychroma.com/)
- [Streamlit](https://streamlit.io/)

---

## ğŸ›¡ï¸ License

This project is licensed under the [MIT License](LICENSE). Feel free to use, modify, and share with attribution.

---
## ğŸ“¢ Connect with Me

Let's collaborate! Connect with me on:

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/v-rithul-06b5632b6/)  

ğŸš€ **Happy Coding!**
